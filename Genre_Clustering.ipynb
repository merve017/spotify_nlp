{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_artists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-4.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m \u001b[39m# TF-IDF Vectorization\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m tfidf_vectorizer \u001b[39m=\u001b[39m TfidfVectorizer(tokenizer\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x, lowercase\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m tfidf_matrix \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39mfit_transform(df_artists[\u001b[39m'\u001b[39m\u001b[39mlemmatized_genres\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m \u001b[39m# KMeans Clustering\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=10'>11</a>\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_artists' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_artists['lemmatized_genres'])\n",
    "\n",
    "# KMeans Clustering\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(tfidf_matrix)\n",
    "df_artists['kmeans_labels'] = kmeans_labels\n",
    "\n",
    "# DBSCAN Clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5, metric='cosine')\n",
    "dbscan_labels = dbscan.fit_predict(tfidf_matrix)\n",
    "df_artists['dbscan_labels'] = dbscan_labels\n",
    "\n",
    "# Visualization using Word Cloud for KMeans\n",
    "for i in range(8):\n",
    "    cluster_genres = df_artists[df_artists['kmeans_labels'] == i]['lemmatized_genres']\n",
    "    all_genres_text = ' '.join([' '.join(genre) for genre in cluster_genres])\n",
    "    \n",
    "    wordcloud = WordCloud(width=800, height=400).generate(all_genres_text)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Genres Word Cloud for KMeans Cluster {i}')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K_range = range(1,15) # testing from 1 to 14 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeanModel = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeanModel.fit(tfidf_matrix)\n",
    "    distortions.append(kmeanModel.inertia_) # inertia is the sum of squared distances to the closest centroid for each point\n",
    "\n",
    "# Plotting the Elbow graph\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(K_range, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure that the artist popularity and followers columns are numeric\n",
    "df_artists['artist_popularity'] = pd.to_numeric(df_artists['artist_popularity'], errors='coerce')\n",
    "df_artists['followers'] = pd.to_numeric(df_artists['followers'], errors='coerce')\n",
    "\n",
    "# Drop NaN values from artist_popularity and followers columns\n",
    "df_artists.dropna(subset=['artist_popularity', 'followers'], inplace=True)\n",
    "\n",
    "# Function to analyze clusters\n",
    "def analyze_cluster(cluster_column):\n",
    "    # Group by the cluster labels and get mean of artist_popularity and followers\n",
    "    cluster_analysis = df_artists.groupby(cluster_column).agg(\n",
    "        Average_Popularity=pd.NamedAgg(column='artist_popularity', aggfunc=np.mean),\n",
    "        Average_Followers=pd.NamedAgg(column='followers', aggfunc=np.mean),\n",
    "        Unique_Artists=pd.NamedAgg(column='id', aggfunc=pd.Series.nunique),\n",
    "        Unique_Genres=pd.NamedAgg(column='cleaned_genres', aggfunc=lambda x: len(set(x.sum())))\n",
    "    ).reset_index()\n",
    "\n",
    "    return cluster_analysis\n",
    "\n",
    "# Analyze KMeans Clusters\n",
    "kmeans_analysis = analyze_cluster('kmeans_labels')\n",
    "print(\"KMeans Cluster Analysis:\\n\", kmeans_analysis)\n",
    "\n",
    "# Analyze DBSCAN Clusters\n",
    "dbscan_analysis = analyze_cluster('dbscan_labels')\n",
    "print(\"\\nDBSCAN Cluster Analysis:\\n\", dbscan_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Finding the best epsilon based on silhouette score and number of clusters\n",
    "best_epsilon = 0\n",
    "best_score = -1\n",
    "epsilons = np.linspace(0.1, 1, 10)  # 10 different epsilon values between 0.1 and 1\n",
    "\n",
    "for eps in epsilons:\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=5, metric='cosine')\n",
    "    dbscan_labels = dbscan.fit_predict(tfidf_matrix)\n",
    "    \n",
    "    # Calculate silhouette score excluding the noise (-1 labels) if there is more than 1 cluster found\n",
    "    num_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "    if num_clusters > 1 and num_clusters : #<= 10:\n",
    "        score = silhouette_score(tfidf_matrix, dbscan_labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_epsilon = eps\n",
    "\n",
    "# Applying DBSCAN with the best epsilon\n",
    "dbscan = DBSCAN(eps=best_epsilon, min_samples=5, metric='cosine')\n",
    "dbscan_labels = dbscan.fit_predict(tfidf_matrix)\n",
    "df_artists['dbscan_labels'] = dbscan_labels\n",
    "\n",
    "# Visualization using Word Cloud for DBSCAN\n",
    "max_label = max(dbscan_labels)\n",
    "for i in range(-1, max_label+1):\n",
    "    cluster_genres = df_artists[df_artists['dbscan_labels'] == i]['cleaned_genres']\n",
    "    all_genres_text = ' '.join([' '.join(genre) for genre in cluster_genres])\n",
    "    \n",
    "    wordcloud = WordCloud(width=800, height=400).generate(all_genres_text)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
