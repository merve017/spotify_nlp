{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import numpy as np\n",
    "from gensim.models import FastText\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/1371305762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['lyrics_clean'] = filtered_df['lyrics'].str.lower()\n",
      "/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/1371305762.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
      "/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/1371305762.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
      "/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/1371305762.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(remove_stopwords)\n",
      "/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/1371305762.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(tokenize_text)\n",
      "/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/1371305762.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(lambda words: [lemmatizer.lemmatize(word) for word in words])\n",
      "/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/1371305762.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['lyrics_clean_untok'] = filtered_df['lyrics_clean'].apply(' '.join)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3803, in get_loc\n",
      "    raise\n",
      "  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'duration_s'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/1371305762.py\", line 50, in <module>\n",
      "    filtered_df= filtered_df[(filtered_df['duration_s'] >= 90) & (filtered_df['duration_s'] <= 600)]\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py\", line 3805, in __getitem__\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n",
      "    _index_shared_docs[\n",
      "KeyError: 'duration_s'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2052, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "#read tracks_spotify_lang - \n",
    "#the file contains the detected language created with the get_language script\n",
    "tracks_lang=pd.read_csv('data/tracks_spotify_lang.csv')\n",
    "#Remove rows of repeating lyrics\n",
    "tracks_lang_no_dup = tracks_lang.drop_duplicates(subset='lyrics', keep='first').reset_index()\n",
    "\n",
    "#get counts of languages\n",
    "tracks_lang_no_dup['language'].value_counts().head(10)\n",
    "\n",
    "#filter for only the english ones\n",
    "filtered_df = tracks_lang_no_dup[tracks_lang_no_dup['language'].isin(['en'])]\n",
    "\n",
    "#lowercasing the lyrics and saving them in new column\n",
    "filtered_df['lyrics_clean'] = filtered_df['lyrics'].str.lower()\n",
    "#removing digits\n",
    "filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "#removing punctuation\n",
    "filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "#extend stopwords\n",
    "new_stop_words = ['aba','ooh','yeah','hey','whoa','woah', 'ohh', 'was', 'mmm', 'oooh','yah','yeh', 'hmm','deh','doh','jah','wa','la','na','oh','em','da','dem','mi','di','fi','gyal','dey','ey','eh','inna','nuh','pon','ba','ye','de','weh','gal','oo','bam','wid','mek','seh','aah','li','ni','waan','wey']\n",
    "\n",
    "#define a function that removes english stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(new_stop_words) \n",
    "    words = word_tokenize(text)\n",
    "    return \" \".join([word for word in words if word.lower() not in stop_words])\n",
    "\n",
    "#define a funtion that tokenizes the lyrics \n",
    "def tokenize_text(text):\n",
    "    return nltk.word_tokenize(str(text))\n",
    "\n",
    "#apply the defined funtions\n",
    "filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(remove_stopwords)\n",
    "filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(tokenize_text)\n",
    "\n",
    "#lemmatizing lyrics\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "filtered_df['lyrics_clean'] = filtered_df['lyrics_clean'].apply(lambda words: [lemmatizer.lemmatize(word) for word in words])\n",
    "\n",
    "#Join list items into a single string without commas 'untokenize'\n",
    "filtered_df['lyrics_clean_untok'] = filtered_df['lyrics_clean'].apply(' '.join)\n",
    "\n",
    "#eliminate rows that contain characters outside the usual English alphabet\n",
    "pattern = '^[a-zA-Z\\s,.;?!-]*$'\n",
    "filtered_df = filtered_df.dropna(subset=['lyrics_clean_untok'])\n",
    "filtered_df = filtered_df[filtered_df['lyrics_clean_untok'].str.contains(pattern)]\n",
    "\n",
    "#filter the data based on duration and word count\n",
    "filtered_df= filtered_df[(filtered_df['duration_s'] >= 90) & (filtered_df['duration_s'] <= 600)]\n",
    "filtered_df= filtered_df_short[(filtered_df_short['word_count'] >= 500) & (filtered_df_short['word_count'] <= 6000)]\n",
    "\n",
    "filtered_df['lyrics_str'] = filtered_df['lyrics'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3803, in get_loc\n",
      "    raise\n",
      "  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'lyrics_str'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/60/s86dq17j5zd4vn2hf6ywd3200000gn/T/ipykernel_46582/55503419.py\", line 4, in <module>\n",
      "    df_tfidf = vectorizer.fit_transform(filtered_df['lyrics_str'])\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py\", line 3805, in __getitem__\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n",
      "    _index_shared_docs[\n",
      "KeyError: 'lyrics_str'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2052, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/tomtom_ghost/opt/anaconda3/envs/py310/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "df_tfidf = vectorizer.fit_transform(filtered_df['lyrics_str'])\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec(sentences=filtered_df['lyrics_clean'].tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_sentence_vector(words):\n",
    "    word_vectors = [model_w2v.wv[word] for word in words if word in model_w2v.wv.index_to_key]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(model_w2v.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "filtered_df['w2v_vector'] = filtered_df['lyrics_clean'].apply(get_sentence_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/3n7wxjyn0rl9rrhzmyw8mb7w0000gn/T/ipykernel_19875/3474118581.py:9: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n",
      "/var/folders/bf/3n7wxjyn0rl9rrhzmyw8mb7w0000gn/T/ipykernel_19875/3474118581.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['glove_vector'] = filtered_df['lyrics_clean'].apply(get_glove_sentence_vector)\n"
     ]
    }
   ],
   "source": [
    "# You'll need to convert the GloVe file format to word2vec format\n",
    "# You can download pre-trained GloVe embeddings from the GloVe website\n",
    "glove_input_file = 'glove.6B.100d.txt'  # Modify the path as per your downloaded model\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "# Load the model\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "\n",
    "def get_glove_sentence_vector(words):\n",
    "    word_vectors = [glove_model[word] for word in words if word in glove_model.key_to_index]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(glove_model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "filtered_df['glove_vector'] = filtered_df['lyrics_clean'].apply(get_glove_sentence_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/3n7wxjyn0rl9rrhzmyw8mb7w0000gn/T/ipykernel_19875/3247512462.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['ft_vector'] = filtered_df['lyrics_clean'].apply(get_ft_sentence_vector)\n"
     ]
    }
   ],
   "source": [
    "model_ft = FastText(vector_size=100, window=5, min_count=1, sentences=filtered_df['lyrics_clean'].tolist(), epochs=10)\n",
    "\n",
    "def get_ft_sentence_vector(words):\n",
    "    word_vectors = [model_ft.wv[word] for word in words if word in model_ft.wv.index_to_key]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(model_ft.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "filtered_df['ft_vector'] = filtered_df['lyrics_clean'].apply(get_ft_sentence_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/3n7wxjyn0rl9rrhzmyw8mb7w0000gn/T/ipykernel_19875/794095595.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['d2v_vector'] = [model_d2v.dv[i] for i in range(len(filtered_df['lyrics_clean']))]\n"
     ]
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(filtered_df['lyrics_clean'].tolist())]\n",
    "model_d2v = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=100)\n",
    "model_d2v.build_vocab(documents)\n",
    "model_d2v.train(documents, total_examples=model_d2v.corpus_count, epochs=model_d2v.epochs)\n",
    "\n",
    "filtered_df['d2v_vector'] = [model_d2v.dv[i] for i in range(len(filtered_df['lyrics_clean']))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Embeddings (sBert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec77e12db23a417b9eb72ae688428aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)001fa/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d982537d1f4a009c39e422161e344d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa8f9b1128c4fffb26eb6bef9a84555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3bbb8001fa/README.md:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6779846416074838aeb5c28c17658a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bb8001fa/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95456715fbb6496ea5dd7165f4f53de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71d40ea3b29457c97943db352419045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d4c5db077c4f6f8c543f4a67261d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a828d757d8b04092b096abc0b7d6a887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e5dadb85874551b9b13748d52b55e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)001fa/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f8c44b9e624309bab4784cac4f6fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09da61c3cb164e1c85ac782e0a254e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3bbb8001fa/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce11d7bd9c0840118293c607c4745b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b8001fa/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/3n7wxjyn0rl9rrhzmyw8mb7w0000gn/T/ipykernel_19875/2840678984.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['sbert_vector'] = filtered_df['lyrics_clean'].apply(lambda x: model.encode(' '.join(x)))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "filtered_df['sbert_vector'] = filtered_df['lyrics_clean'].apply(lambda x: model.encode(' '.join(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>album_id</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>artists_id</th>\n",
       "      <th>available_markets</th>\n",
       "      <th>country</th>\n",
       "      <th>danceability</th>\n",
       "      <th>disc_number</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>type</th>\n",
       "      <th>language</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lyrics_clean</th>\n",
       "      <th>lyrics_str</th>\n",
       "      <th>w2v_vector</th>\n",
       "      <th>glove_vector</th>\n",
       "      <th>d2v_vector</th>\n",
       "      <th>ft_vector</th>\n",
       "      <th>sbert_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.29400</td>\n",
       "      <td>0D3QufeCudpQANOR7luqdr</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/5qlj...</td>\n",
       "      <td>['3mxJuHRn2ZWD5OofvJtDZY']</td>\n",
       "      <td>['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>235584.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>[perhaps, bound, restless, always, yearning, n...</td>\n",
       "      <td>perhaps bound restless always yearning never s...</td>\n",
       "      <td>[0.6544756, -0.3229556, -0.139516, 0.22122717,...</td>\n",
       "      <td>[0.016300496, 0.34271294, 0.37241003, -0.16385...</td>\n",
       "      <td>[-1.5367717, -2.4504938, 0.15364909, -3.299925...</td>\n",
       "      <td>[1.0889084, -0.17906623, -1.5707855, -1.269119...</td>\n",
       "      <td>[-0.046746217, -0.17634994, 0.40579668, -0.019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.86300</td>\n",
       "      <td>1bcqsH5UyTBzmh9YizdsBE</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/3VAX...</td>\n",
       "      <td>['4xWMewm6CYMstu0sPgd9jJ']</td>\n",
       "      <td>['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>656960.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>[gods, godsdo, know, stronger, native, proverb...</td>\n",
       "      <td>gods godsdo know stronger native proverb east ...</td>\n",
       "      <td>[0.22900137, -0.011180511, 0.11696933, -0.0378...</td>\n",
       "      <td>[-0.012346554, 0.142385, 0.20282121, -0.249358...</td>\n",
       "      <td>[2.0670466, -1.9952976, -0.78856546, -1.299497...</td>\n",
       "      <td>[0.6557791, 0.046614774, -1.3376333, -0.805199...</td>\n",
       "      <td>[0.18349041, 0.17910825, -0.0504529, -0.278700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>4tKijjmxGClg4JOLAyo2qE</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1L3Y...</td>\n",
       "      <td>['3hYaK5FF3YAglCj5HZgBnP']</td>\n",
       "      <td>['GB']</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>492840.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>[closed, love, didnt, need, pain, twice, enoug...</td>\n",
       "      <td>closed love didnt need pain twice enough vain ...</td>\n",
       "      <td>[0.6947316, -0.28599197, -0.29491928, 0.682063...</td>\n",
       "      <td>[-0.07529787, 0.18532664, 0.25859946, -0.17300...</td>\n",
       "      <td>[-1.1369686, 0.56759566, -3.5360346, -0.316745...</td>\n",
       "      <td>[0.71569294, -0.3852827, -1.5801319, 0.3134563...</td>\n",
       "      <td>[-0.27127653, 0.33813798, 0.26504812, 0.256099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.76300</td>\n",
       "      <td>6FeJF5r8roonnKraJxr4oB</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6aCe...</td>\n",
       "      <td>['2KQsUB9DRBcJk17JWX1eXD']</td>\n",
       "      <td>['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>316578.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>[pain, n, uncomfortable, frame, mind, may, phy...</td>\n",
       "      <td>pain n uncomfortable frame mind may physical b...</td>\n",
       "      <td>[-0.03170229, -0.06108123, 0.18263377, -0.0254...</td>\n",
       "      <td>[-0.07350073, 0.19990432, 0.21373656, 0.010531...</td>\n",
       "      <td>[-1.0665642, 2.9360483, 2.1036134, -2.8190637,...</td>\n",
       "      <td>[0.33878967, -0.22557345, -0.9858403, -0.97439...</td>\n",
       "      <td>[0.05471897, 0.29905123, 0.18562856, -0.030469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.97100</td>\n",
       "      <td>7CCwkPweMxKq8yWkVerH6T</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/4PrA...</td>\n",
       "      <td>['3kzwYV3OCB010YfXMF0Avt']</td>\n",
       "      <td>['AE', 'AR', 'BH', 'BO', 'BR', 'CL', 'CO', 'CR...</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>183653.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>[ocean, wed, wading, distance, would, water, c...</td>\n",
       "      <td>ocean wed wading distance would water creating...</td>\n",
       "      <td>[0.23468369, 0.123190805, 0.14694338, 0.348222...</td>\n",
       "      <td>[-0.2001696, 0.29664358, 0.30343485, -0.061161...</td>\n",
       "      <td>[-2.7153978, 0.94972116, 0.113015994, 0.052836...</td>\n",
       "      <td>[0.7678717, -0.062007383, -0.8720988, -1.32967...</td>\n",
       "      <td>[0.07439018, 0.18220776, 0.2588866, 0.04634476...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40811</th>\n",
       "      <td>101933</td>\n",
       "      <td>0.00837</td>\n",
       "      <td>4PXy3cBCNeY0ZVKTOGi9Cw</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0ujk...</td>\n",
       "      <td>['3yW6jTzGjHUUkLvLkjLOVn']</td>\n",
       "      <td>['AU', 'NZ']</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251253.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>[black, fingernails, red, wine, wan, na, make,...</td>\n",
       "      <td>black fingernails red wine wan na make mine lo...</td>\n",
       "      <td>[0.44811702, -0.100758, 0.2660182, 0.06938852,...</td>\n",
       "      <td>[-0.048288547, 0.2610699, 0.3593745, -0.176603...</td>\n",
       "      <td>[1.925146, -2.844099, 1.6665615, -1.1851282, -...</td>\n",
       "      <td>[0.5904623, 0.23795933, -1.4836384, -0.4944968...</td>\n",
       "      <td>[0.14479434, 0.21599376, 0.22885923, 0.2102713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40812</th>\n",
       "      <td>101934</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>1M9n4vCmOH4lbcHrpt21Qy</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/4e5w...</td>\n",
       "      <td>['6n3YUZcayLRuAunJUUelvz']</td>\n",
       "      <td>['AU', 'NZ']</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178893.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>[got, killed, black, bugs, video, game, go, do...</td>\n",
       "      <td>got killed black bugs video game go doesnt mea...</td>\n",
       "      <td>[0.82594174, 0.50977314, -0.18910752, 0.247966...</td>\n",
       "      <td>[0.019538017, 0.035030667, 0.330982, -0.373247...</td>\n",
       "      <td>[-0.7555603, -1.3426641, -0.93408245, 0.435649...</td>\n",
       "      <td>[1.4542688, 0.5694922, -0.11898839, 0.1971883,...</td>\n",
       "      <td>[-0.12921098, 0.4119401, 0.42094037, -0.415113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40813</th>\n",
       "      <td>101936</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>511p6iaCuK8Sr0BYdpcfkq</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2RDg...</td>\n",
       "      <td>['4iudEcmuPlYNdbP3e1bdn1']</td>\n",
       "      <td>['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>226107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>[maybes, babys, got, rabies, sitting, ball, mi...</td>\n",
       "      <td>maybes babys got rabies sitting ball middle an...</td>\n",
       "      <td>[0.29831922, -0.57115144, -0.44154608, 0.74772...</td>\n",
       "      <td>[0.0063904664, -0.06470064, 0.3809119, -0.4926...</td>\n",
       "      <td>[-2.2750988, 0.94128, -0.0103180995, -0.169187...</td>\n",
       "      <td>[0.5732491, -0.58380264, -0.9342053, 1.0837853...</td>\n",
       "      <td>[0.119946614, 0.15521228, 0.2767093, 0.3715858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40814</th>\n",
       "      <td>101937</td>\n",
       "      <td>0.33300</td>\n",
       "      <td>7H3Bgvb3hs4vvLwccHDRlr</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1pXt...</td>\n",
       "      <td>['023YMawCG3OvACmRjWxLWC']</td>\n",
       "      <td>['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>224133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>[walking, street, evil, eye, thoughts, head, m...</td>\n",
       "      <td>walking street evil eye thoughts head making f...</td>\n",
       "      <td>[0.40733936, -0.038820736, 0.26862425, 0.36641...</td>\n",
       "      <td>[-0.032217294, 0.16006291, 0.3003769, -0.28832...</td>\n",
       "      <td>[-1.1828336, 0.18043165, 1.1037525, -1.3816043...</td>\n",
       "      <td>[0.251497, -0.2612326, -1.1063672, -0.5885462,...</td>\n",
       "      <td>[-0.1872387, -0.010242814, 0.22958818, 0.09279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40815</th>\n",
       "      <td>101938</td>\n",
       "      <td>0.02840</td>\n",
       "      <td>3oieBBYbUOve0VpxTCpHr1</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6MzG...</td>\n",
       "      <td>['6OgAO7QYncP5feMijPxBxi']</td>\n",
       "      <td>['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251787.0</td>\n",
       "      <td>...</td>\n",
       "      <td>track</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>[theres, enough, hours, day, tell, youre, gett...</td>\n",
       "      <td>theres enough hours day tell youre getting way...</td>\n",
       "      <td>[0.39492735, 0.04021288, 0.12430246, 0.4468820...</td>\n",
       "      <td>[-0.08143048, 0.34270152, 0.32897347, -0.25049...</td>\n",
       "      <td>[0.16657254, 0.2414234, 1.1033816, -1.7151266,...</td>\n",
       "      <td>[0.8096032, -0.12605281, -1.1806523, -0.848713...</td>\n",
       "      <td>[-0.3005313, 0.06529173, -0.12648864, 0.139733...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25732 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  acousticness                album_id  \\\n",
       "0           0       0.29400  0D3QufeCudpQANOR7luqdr   \n",
       "1           1       0.86300  1bcqsH5UyTBzmh9YizdsBE   \n",
       "2           2       0.75000  4tKijjmxGClg4JOLAyo2qE   \n",
       "3           3       0.76300  6FeJF5r8roonnKraJxr4oB   \n",
       "4           5       0.97100  7CCwkPweMxKq8yWkVerH6T   \n",
       "...       ...           ...                     ...   \n",
       "40811  101933       0.00837  4PXy3cBCNeY0ZVKTOGi9Cw   \n",
       "40812  101934       0.00564  1M9n4vCmOH4lbcHrpt21Qy   \n",
       "40813  101936       0.00451  511p6iaCuK8Sr0BYdpcfkq   \n",
       "40814  101937       0.33300  7H3Bgvb3hs4vvLwccHDRlr   \n",
       "40815  101938       0.02840  3oieBBYbUOve0VpxTCpHr1   \n",
       "\n",
       "                                            analysis_url  \\\n",
       "0      https://api.spotify.com/v1/audio-analysis/5qlj...   \n",
       "1      https://api.spotify.com/v1/audio-analysis/3VAX...   \n",
       "2      https://api.spotify.com/v1/audio-analysis/1L3Y...   \n",
       "3      https://api.spotify.com/v1/audio-analysis/6aCe...   \n",
       "4      https://api.spotify.com/v1/audio-analysis/4PrA...   \n",
       "...                                                  ...   \n",
       "40811  https://api.spotify.com/v1/audio-analysis/0ujk...   \n",
       "40812  https://api.spotify.com/v1/audio-analysis/4e5w...   \n",
       "40813  https://api.spotify.com/v1/audio-analysis/2RDg...   \n",
       "40814  https://api.spotify.com/v1/audio-analysis/1pXt...   \n",
       "40815  https://api.spotify.com/v1/audio-analysis/6MzG...   \n",
       "\n",
       "                       artists_id  \\\n",
       "0      ['3mxJuHRn2ZWD5OofvJtDZY']   \n",
       "1      ['4xWMewm6CYMstu0sPgd9jJ']   \n",
       "2      ['3hYaK5FF3YAglCj5HZgBnP']   \n",
       "3      ['2KQsUB9DRBcJk17JWX1eXD']   \n",
       "4      ['3kzwYV3OCB010YfXMF0Avt']   \n",
       "...                           ...   \n",
       "40811  ['3yW6jTzGjHUUkLvLkjLOVn']   \n",
       "40812  ['6n3YUZcayLRuAunJUUelvz']   \n",
       "40813  ['4iudEcmuPlYNdbP3e1bdn1']   \n",
       "40814  ['023YMawCG3OvACmRjWxLWC']   \n",
       "40815  ['6OgAO7QYncP5feMijPxBxi']   \n",
       "\n",
       "                                       available_markets country  \\\n",
       "0      ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      BE   \n",
       "1      ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      BE   \n",
       "2                                                 ['GB']      BE   \n",
       "3      ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      BE   \n",
       "4      ['AE', 'AR', 'BH', 'BO', 'BR', 'CL', 'CO', 'CR...      BE   \n",
       "...                                                  ...     ...   \n",
       "40811                                       ['AU', 'NZ']      AR   \n",
       "40812                                       ['AU', 'NZ']      AR   \n",
       "40813  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      AR   \n",
       "40814  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      AR   \n",
       "40815  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      AR   \n",
       "\n",
       "       danceability  disc_number  duration_ms  ...   type language confidence  \\\n",
       "0             0.698          1.0     235584.0  ...  track       en   0.999995   \n",
       "1             0.719          1.0     656960.0  ...  track       en   0.999997   \n",
       "2             0.466          1.0     492840.0  ...  track       en   0.999995   \n",
       "3             0.719          1.0     316578.0  ...  track       en   0.999998   \n",
       "4             0.367          1.0     183653.0  ...  track       en   0.999997   \n",
       "...             ...          ...          ...  ...    ...      ...        ...   \n",
       "40811         0.553          1.0     251253.0  ...  track       en   0.999997   \n",
       "40812         0.602          1.0     178893.0  ...  track       en   0.999998   \n",
       "40813         0.539          1.0     226107.0  ...  track       en   0.999997   \n",
       "40814         0.716          1.0     224133.0  ...  track       en   0.999998   \n",
       "40815         0.500          1.0     251787.0  ...  track       en   0.999998   \n",
       "\n",
       "                                            lyrics_clean  \\\n",
       "0      [perhaps, bound, restless, always, yearning, n...   \n",
       "1      [gods, godsdo, know, stronger, native, proverb...   \n",
       "2      [closed, love, didnt, need, pain, twice, enoug...   \n",
       "3      [pain, n, uncomfortable, frame, mind, may, phy...   \n",
       "4      [ocean, wed, wading, distance, would, water, c...   \n",
       "...                                                  ...   \n",
       "40811  [black, fingernails, red, wine, wan, na, make,...   \n",
       "40812  [got, killed, black, bugs, video, game, go, do...   \n",
       "40813  [maybes, babys, got, rabies, sitting, ball, mi...   \n",
       "40814  [walking, street, evil, eye, thoughts, head, m...   \n",
       "40815  [theres, enough, hours, day, tell, youre, gett...   \n",
       "\n",
       "                                              lyrics_str  \\\n",
       "0      perhaps bound restless always yearning never s...   \n",
       "1      gods godsdo know stronger native proverb east ...   \n",
       "2      closed love didnt need pain twice enough vain ...   \n",
       "3      pain n uncomfortable frame mind may physical b...   \n",
       "4      ocean wed wading distance would water creating...   \n",
       "...                                                  ...   \n",
       "40811  black fingernails red wine wan na make mine lo...   \n",
       "40812  got killed black bugs video game go doesnt mea...   \n",
       "40813  maybes babys got rabies sitting ball middle an...   \n",
       "40814  walking street evil eye thoughts head making f...   \n",
       "40815  theres enough hours day tell youre getting way...   \n",
       "\n",
       "                                              w2v_vector  \\\n",
       "0      [0.6544756, -0.3229556, -0.139516, 0.22122717,...   \n",
       "1      [0.22900137, -0.011180511, 0.11696933, -0.0378...   \n",
       "2      [0.6947316, -0.28599197, -0.29491928, 0.682063...   \n",
       "3      [-0.03170229, -0.06108123, 0.18263377, -0.0254...   \n",
       "4      [0.23468369, 0.123190805, 0.14694338, 0.348222...   \n",
       "...                                                  ...   \n",
       "40811  [0.44811702, -0.100758, 0.2660182, 0.06938852,...   \n",
       "40812  [0.82594174, 0.50977314, -0.18910752, 0.247966...   \n",
       "40813  [0.29831922, -0.57115144, -0.44154608, 0.74772...   \n",
       "40814  [0.40733936, -0.038820736, 0.26862425, 0.36641...   \n",
       "40815  [0.39492735, 0.04021288, 0.12430246, 0.4468820...   \n",
       "\n",
       "                                            glove_vector  \\\n",
       "0      [0.016300496, 0.34271294, 0.37241003, -0.16385...   \n",
       "1      [-0.012346554, 0.142385, 0.20282121, -0.249358...   \n",
       "2      [-0.07529787, 0.18532664, 0.25859946, -0.17300...   \n",
       "3      [-0.07350073, 0.19990432, 0.21373656, 0.010531...   \n",
       "4      [-0.2001696, 0.29664358, 0.30343485, -0.061161...   \n",
       "...                                                  ...   \n",
       "40811  [-0.048288547, 0.2610699, 0.3593745, -0.176603...   \n",
       "40812  [0.019538017, 0.035030667, 0.330982, -0.373247...   \n",
       "40813  [0.0063904664, -0.06470064, 0.3809119, -0.4926...   \n",
       "40814  [-0.032217294, 0.16006291, 0.3003769, -0.28832...   \n",
       "40815  [-0.08143048, 0.34270152, 0.32897347, -0.25049...   \n",
       "\n",
       "                                              d2v_vector  \\\n",
       "0      [-1.5367717, -2.4504938, 0.15364909, -3.299925...   \n",
       "1      [2.0670466, -1.9952976, -0.78856546, -1.299497...   \n",
       "2      [-1.1369686, 0.56759566, -3.5360346, -0.316745...   \n",
       "3      [-1.0665642, 2.9360483, 2.1036134, -2.8190637,...   \n",
       "4      [-2.7153978, 0.94972116, 0.113015994, 0.052836...   \n",
       "...                                                  ...   \n",
       "40811  [1.925146, -2.844099, 1.6665615, -1.1851282, -...   \n",
       "40812  [-0.7555603, -1.3426641, -0.93408245, 0.435649...   \n",
       "40813  [-2.2750988, 0.94128, -0.0103180995, -0.169187...   \n",
       "40814  [-1.1828336, 0.18043165, 1.1037525, -1.3816043...   \n",
       "40815  [0.16657254, 0.2414234, 1.1033816, -1.7151266,...   \n",
       "\n",
       "                                               ft_vector  \\\n",
       "0      [1.0889084, -0.17906623, -1.5707855, -1.269119...   \n",
       "1      [0.6557791, 0.046614774, -1.3376333, -0.805199...   \n",
       "2      [0.71569294, -0.3852827, -1.5801319, 0.3134563...   \n",
       "3      [0.33878967, -0.22557345, -0.9858403, -0.97439...   \n",
       "4      [0.7678717, -0.062007383, -0.8720988, -1.32967...   \n",
       "...                                                  ...   \n",
       "40811  [0.5904623, 0.23795933, -1.4836384, -0.4944968...   \n",
       "40812  [1.4542688, 0.5694922, -0.11898839, 0.1971883,...   \n",
       "40813  [0.5732491, -0.58380264, -0.9342053, 1.0837853...   \n",
       "40814  [0.251497, -0.2612326, -1.1063672, -0.5885462,...   \n",
       "40815  [0.8096032, -0.12605281, -1.1806523, -0.848713...   \n",
       "\n",
       "                                            sbert_vector  \n",
       "0      [-0.046746217, -0.17634994, 0.40579668, -0.019...  \n",
       "1      [0.18349041, 0.17910825, -0.0504529, -0.278700...  \n",
       "2      [-0.27127653, 0.33813798, 0.26504812, 0.256099...  \n",
       "3      [0.05471897, 0.29905123, 0.18562856, -0.030469...  \n",
       "4      [0.07439018, 0.18220776, 0.2588866, 0.04634476...  \n",
       "...                                                  ...  \n",
       "40811  [0.14479434, 0.21599376, 0.22885923, 0.2102713...  \n",
       "40812  [-0.12921098, 0.4119401, 0.42094037, -0.415113...  \n",
       "40813  [0.119946614, 0.15521228, 0.2767093, 0.3715858...  \n",
       "40814  [-0.1872387, -0.010242814, 0.22958818, 0.09279...  \n",
       "40815  [-0.3005313, 0.06529173, -0.12648864, 0.139733...  \n",
       "\n",
       "[25732 rows x 41 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
